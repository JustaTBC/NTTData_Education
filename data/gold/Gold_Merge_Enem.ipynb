{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a929c2-2a67-42a4-a870-7912d0ad6b41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_alunos = spark.table(\"nttdataeducacao.silver.resultados_2024\") \n",
    "df_escolas = spark.table(\"nttdataeducacao.silver.escolas_2024\")   \n",
    "\n",
    "# 2. O Join (Cruzamento)\n",
    "# A chave é: school_id (Alunos) == cod_entid (Escolas)\n",
    "df_enrich = df_alunos.join(\n",
    "    df_escolas,\n",
    "    df_alunos.school_id == df_escolas.cod_entid,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# 3. Seleção das Colunas Importantes (Para não ficar uma tabela gigante com 200 colunas)\n",
    "df_final = df_enrich.select(\n",
    "    # Dados do Aluno\n",
    "    df_alunos[\"*\"], # Traz tudo do aluno\n",
    "    \n",
    "    # Dados da Escola (Enriquecimento)\n",
    "    df_escolas[\"nome_entid\"].alias(\"nome_escola\"),\n",
    "    df_escolas[\"dependencia\"].alias(\"tipo_rede_censo\"), # Federal, Estadual...\n",
    "    df_escolas[\"localizacao\"].alias(\"zona_escola\")      # Urbana/Rural\n",
    ")\n",
    "\n",
    "display(df_final.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "964b213c-78d6-4f13-b25d-65e671f29434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# 1. REAPROVEITE: Leitura e Join (Isso aqui é igual ao seu código de Merge)\n",
    "df_resultados = spark.table(\"nttdataeducacao.gold.agg_ranking_escolas\")\n",
    "df_escolas = spark.table(\"nttdataeducacao.silver.escolas_2024\")\n",
    "\n",
    "# Join padrão (Inner Join para pegar só quem tem nas duas)\n",
    "df_join = df_resultados.join(\n",
    "    df_escolas,\n",
    "    df_resultados.school_id == df_escolas.cod_entid\n",
    ")\n",
    "\n",
    "# 2. NOVO: A Lógica de Comparação\n",
    "# O ENEM usa números (1,2,3,4) e o Censo usa texto ('Federal', etc).\n",
    "# Precisamos traduzir o número para texto para poder comparar.\n",
    "\n",
    "df_check = df_join.withColumn(\n",
    "    \"tipo_enem_traduzido\",\n",
    "    when(col(\"school_type_id\") == 1, \"Federal\")\n",
    "    .when(col(\"school_type_id\") == 2, \"Estadual\")\n",
    "    .when(col(\"school_type_id\") == 3, \"Municipal\")\n",
    "    .when(col(\"school_type_id\") == 4, \"Privada\")\n",
    "    .otherwise(\"Outros\")\n",
    ").select(\n",
    "    \"school_id\",\n",
    "    \"school_city\",\n",
    "    col(\"tipo_enem_traduzido\").alias(\"O_que_o_ENEM_diz\"),\n",
    "    col(\"dependencia\").alias(\"O_que_o_Censo_diz\")\n",
    ")\n",
    "\n",
    "# 3. O Filtro da Mentira (Onde eles discordam)\n",
    "df_divergencias = df_check.filter(\n",
    "    col(\"O_que_o_ENEM_diz\") != col(\"O_que_o_Censo_diz\")\n",
    ")\n",
    "\n",
    "# Mostra o resultado\n",
    "print(f\"Total de escolas com divergência: {df_divergencias.count()}\")\n",
    "display(df_divergencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad6ad26-9e34-402e-955f-090538c36ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, round, count, desc\n",
    "\n",
    "# 1. Ler a tabela Mestra\n",
    "df_comparacao_final = df_final \\\n",
    "    .filter(col(\"school_id\") != -1) \\\n",
    "    .groupBy(\n",
    "        \"school_id\",      # <--- ADICIONADO AQUI PARA CONFERÊNCIA\n",
    "        \"nome_escola\", \n",
    "        \"school_state\"\n",
    "    ) \\\n",
    "    .agg(\n",
    "        count(\"candidate_id\").alias(\"qtd_alunos\"),\n",
    "        # Médias cruas (precisão total)\n",
    "        avg(\"score_essay\").alias(\"raw_redacao\"),\n",
    "        avg(\"score_math\").alias(\"raw_matematica\"),\n",
    "        avg(\"score_languages\").alias(\"raw_linguagens\"),\n",
    "        avg(\"score_humanities\").alias(\"raw_humanas\"),\n",
    "        avg(\"score_nature\").alias(\"raw_natureza\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"total_preciso\", \n",
    "        col(\"raw_redacao\") + col(\"raw_matematica\") + \n",
    "        col(\"raw_linguagens\") + col(\"raw_humanas\") + col(\"raw_natureza\")\n",
    "    ) \\\n",
    "    .filter(col(\"qtd_alunos\") >= 10) \\\n",
    "    .orderBy(desc(\"total_preciso\")) \\\n",
    "    .limit(10) \\\n",
    "    .select(\n",
    "        col(\"school_id\"), # <--- E ADICIONADO AQUI NA VISUALIZAÇÃO\n",
    "        col(\"nome_escola\"),\n",
    "        col(\"school_state\"),\n",
    "        round(col(\"total_preciso\"), 2).alias(\"Nota_Total_Ranking\"),\n",
    "        # As partes para conferência visual\n",
    "        round(col(\"raw_redacao\"), 0).alias(\"Redacao\"),\n",
    "        round(col(\"raw_matematica\"), 0).alias(\"Matematica\")\n",
    "    )\n",
    "\n",
    "display(df_comparacao_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_Merge_Enem",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

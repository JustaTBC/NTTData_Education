{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a929c2-2a67-42a4-a870-7912d0ad6b41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# 1. Leitura\n",
    "df_alunos = spark.table(\"nttdataeducacao.silver.resultados_2024\")\n",
    "df_escolas = spark.table(\"nttdataeducacao.silver.escolas_2024\")\n",
    "\n",
    "# 2. Join\n",
    "df_enrich = df_alunos.join(\n",
    "    df_escolas,\n",
    "    df_alunos.school_id == df_escolas.cod_entid,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# 3. Seleção com a Correção de Tipo (Cast)\n",
    "df_final = df_enrich.select(\n",
    "    # Dados do Aluno\n",
    "    df_alunos[\"*\"],\n",
    "    \n",
    "    # Dados da Escola\n",
    "    df_escolas[\"nome_entid\"].alias(\"nome_escola\"),\n",
    "    df_escolas[\"dependencia\"].alias(\"tipo_rede_censo\"),\n",
    "    df_escolas[\"localizacao\"].alias(\"zona_escola\"),\n",
    "    \n",
    "    # --- CORREÇÃO AQUI ---\n",
    "    # Convertemos para 'double' antes de comparar com 7\n",
    "    when(col(\"total_ensino_medio\").cast(\"double\") >= 7, \"Sim\") \n",
    "    .when(col(\"total_ensino_medio\").cast(\"double\") < 7, \"Não\")\n",
    "    \n",
    "    # Regra 3: Varredura de Nomes e Siglas\n",
    "    .when(col(\"nome_entid\").contains(\"INTEGRAL\"), \"Sim (Pelo Nome)\")\n",
    "    .when(col(\"nome_entid\").contains(\"EEEMTI\"), \"Sim (Pelo Nome)\") \n",
    "    .when(col(\"nome_entid\").contains(\"EEMTI\"), \"Sim (Pelo Nome)\")  \n",
    "    .when(col(\"nome_entid\").contains(\"CETI\"), \"Sim (Pelo Nome)\")   \n",
    "    .otherwise(\"Não / Não Informado\").alias(\"possui_ensino_integral\"),\n",
    "    \n",
    "    # Mantendo a hora para conferência (já convertida para número)\n",
    "    df_escolas[\"total_ensino_medio\"].cast(\"double\").alias(\"media_horas_diarias\")\n",
    ")\n",
    "\n",
    "# 4. Gravação\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"nttdataeducacao.gold.analytics_enem_completo\")\n",
    "\n",
    "display(df_final.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "964b213c-78d6-4f13-b25d-65e671f29434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df_resultados = spark.table(\"nttdataeducacao.gold.agg_ranking_escolas\")\n",
    "df_escolas = spark.table(\"nttdataeducacao.silver.escolas_2024\")\n",
    "\n",
    "df_join = df_resultados.join(\n",
    "    df_escolas,\n",
    "    df_resultados.school_id == df_escolas.cod_entid\n",
    ")\n",
    "\n",
    "\n",
    "df_check = df_join.withColumn(\n",
    "    \"tipo_enem_traduzido\",\n",
    "    when(col(\"school_type_id\") == 1, \"Federal\")\n",
    "    .when(col(\"school_type_id\") == 2, \"Estadual\")\n",
    "    .when(col(\"school_type_id\") == 3, \"Municipal\")\n",
    "    .when(col(\"school_type_id\") == 4, \"Privada\")\n",
    "    .otherwise(\"Outros\")\n",
    ").select(\n",
    "    \"school_id\",\n",
    "    \"school_city\",\n",
    "    col(\"tipo_enem_traduzido\").alias(\"O_que_o_ENEM_diz\"),\n",
    "    col(\"dependencia\").alias(\"O_que_o_Censo_diz\")\n",
    ")\n",
    "\n",
    "# 3. O Filtro da Mentira (Onde eles discordam)\n",
    "df_divergencias = df_check.filter(\n",
    "    col(\"O_que_o_ENEM_diz\") != col(\"O_que_o_Censo_diz\")\n",
    ")\n",
    "\n",
    "# Mostra o resultado\n",
    "print(f\"Total de escolas com divergência: {df_divergencias.count()}\")\n",
    "display(df_divergencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad6ad26-9e34-402e-955f-090538c36ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, round, count, desc\n",
    "\n",
    "df_final = spark.table(\"nttdataeducacao.gold.analytics_enem_completo\")\n",
    "df_comparacao_final = df_final \\\n",
    "    .filter(col(\"school_id\").isNotNull()) \\\n",
    "    .groupBy(\n",
    "        \"school_id\",\n",
    "        \"nome_escola\", \n",
    "        \"school_state\",\n",
    "        \"school_city\"\n",
    "    ) \\\n",
    "    .agg(\n",
    "        count(\"candidate_id\").alias(\"qtd_alunos\"),\n",
    "        avg(\"score_essay\").alias(\"raw_redacao\"),\n",
    "        avg(\"score_math\").alias(\"raw_matematica\"),\n",
    "        avg(\"score_languages\").alias(\"raw_linguagens\"),\n",
    "        avg(\"score_humanities\").alias(\"raw_humanas\"),\n",
    "        avg(\"score_nature\").alias(\"raw_natureza\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"total_preciso\", \n",
    "        col(\"raw_redacao\") + col(\"raw_matematica\") + \n",
    "        col(\"raw_linguagens\") + col(\"raw_humanas\") + col(\"raw_natureza\")\n",
    "    ) \\\n",
    "    .filter(col(\"qtd_alunos\") >= 10) \\\n",
    "    .orderBy(desc(\"total_preciso\")) \\\n",
    "    .limit(10) \\\n",
    "    .select(\n",
    "        col(\"school_id\"), \n",
    "        col(\"nome_escola\"),\n",
    "        col(\"school_state\"),\n",
    "        col(\"school_city\"),\n",
    "        round(col(\"total_preciso\"), 2).alias(\"Nota_Total_Ranking\"),\n",
    "        round(col(\"raw_redacao\"), 0).alias(\"Redacao\"),\n",
    "        round(col(\"raw_matematica\"), 0).alias(\"Matematica\"),\n",
    "        round(col(\"raw_linguagens\"), 0).alias(\"Linguagens\"),\n",
    "        round(col(\"raw_humanas\"), 0).alias(\"Humanas\"),\n",
    "        round(col(\"raw_natureza\"), 0).alias(\"Natureza\")\n",
    "    )\n",
    "\n",
    "display(df_comparacao_final)\n",
    "\n",
    "df_comparacao_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"nttdataeducacao.gold.agg_ranking_top10_final\")\n",
    "\n",
    "print(\"✅ Tabela salva com sucesso! Pode usar no Dashboard agora.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_Merge_Enem",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
